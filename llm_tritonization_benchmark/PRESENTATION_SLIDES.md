# LLM-Driven Triton Code Generation for TSVC Benchmark

**Automated Infrastructure for GPU Kernel Generation and Validation**

---

# Part 1: Infrastructure Design

## System Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    generate_and_test.py                     â”‚
â”‚                     (Main Pipeline)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â”œâ”€â–º TSVC Function Database (151 functions)
               â”‚   â””â”€ utilities/tsvc_functions_db.py
               â”‚
               â”œâ”€â–º Static Analysis Modules (PET/ISL)
               â”‚   â”œâ”€ WAR Dependencies
               â”‚   â”œâ”€ Statement Overwrites
               â”‚   â”œâ”€ Stream Compaction
               â”‚   â”œâ”€ Loop Unrolling Patterns
               â”‚   â”œâ”€ Early Exit Detection
               â”‚   â”œâ”€ Statement Reordering
               â”‚   â”œâ”€ Scalar Expansion
               â”‚   â”œâ”€ Reduction Detection
               â”‚   â””â”€ Convolution Patterns
               â”‚
               â”œâ”€â–º LLM Generation (Claude Sonnet 4.5)
               â”‚   â”œâ”€ Initial prompt with analysis
               â”‚   â”œâ”€ Retry with error feedback (max 10)
               â”‚   â””â”€ 5+5 reset strategy
               â”‚
               â”œâ”€â–º Test Infrastructure
               â”‚   â”œâ”€ TSVC C reference (compiled shared library)
               â”‚   â”œâ”€ Triton correctness testing
               â”‚   â””â”€ Performance benchmarking vs C reference
               â”‚
               â””â”€â–º Results Collection
                   â”œâ”€ test{N}/llm_triton/  (generated code)
                   â”œâ”€ test{N}/results.json (metrics)
                   â””â”€ FINAL_TEST_RESULTS.md (analysis)
```

---

## Pipeline Flow: Per-Function Processing

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TSVC Function   â”‚ (e.g., s421)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€â–º 1. Extract C code structure
         â”‚      - Kernel loop identification
         â”‚      - Array access patterns
         â”‚      - Local variables
         â”‚
         â”œâ”€â–º 2. Run Static Analysis
         â”‚      - PET: Dependence analysis
         â”‚      - ISL: Parallelization strategy
         â”‚      - Pattern detection (8 modules)
         â”‚
         â”œâ”€â–º 3. Build LLM Prompt
         â”‚      - C code + analysis results
         â”‚      - Triton compilation rules
         â”‚      - Function signature requirements
         â”‚
         â”œâ”€â–º 4. C Reference (Pre-compiled)
         â”‚      - Original TSVC C kernels
         â”‚      - Compiled as shared library (libtsvc_all.so)
         â”‚      - Python wrappers via ctypes
         â”‚
         â”œâ”€â–º 5. Generate Triton Code
         â”‚      â”œâ”€ Attempt 1: Initial generation
         â”‚      â”œâ”€ Attempts 2-5: Retry with errors
         â”‚      â”œâ”€ Attempt 6: Reset context
         â”‚      â””â”€ Attempts 7-10: Fresh tries
         â”‚
         â”œâ”€â–º 6. Test Correctness
         â”‚      - Compare vs TSVC C reference
         â”‚      - Multiple input sizes
         â”‚      - Tolerance: max_error < 1e-3
         â”‚
         â””â”€â–º 7. Benchmark Performance
                - 10 warmup iterations
                - 100 benchmark iterations
                - 60-second timeout per section
                - Record speedup ratio
```

---

## Key Infrastructure Components

### 1. **generate_and_test.py** (Main Pipeline)
- **Lines:** ~2,100
- **Functions:** 40+
- **Key Features:**
  - Automatic TSVC function extraction from C code
  - Integration with 8 static analysis modules
  - Retry logic with error feedback
  - Test harness auto-generation
  - Benchmark infrastructure

### 2. **TSVC Function Database + C Code Parser**
```python
# Database stores minimal info (name + source code)
TSVC_FUNCTIONS = {
    "s421": {
        "name": "s421",
        "loop_code": "for (int i = 0; i < n; i++) { ... }"
    },
    # ... 150 more functions
}

# Properties inferred at runtime via c_code_parser.py:
# - arrays: extracted from array accesses (a[i] patterns)
# - has_offset: detected from index patterns ([i+10], [i-1])
# - has_reduction: detected from accumulation (sum +=, x = x + ...)
# - has_conditional: detected from if statements
# - has_2d_arrays: detected from [i][j] patterns
```

### 3. **Static Analysis Modules** (PET + Custom)
| Module | Purpose | Example Output |
|--------|---------|----------------|
| `compute_war_dependences` | Detect write-after-read | "Save `a[i]` before overwrite" |
| `compute_statement_overwrites` | Detect overwrite patterns | "Use latest value only" |
| `compute_stream_compaction` | Detect if/scatter patterns | "Use atomic operations" |
| `compute_loop_unrolling` | Suggest unroll strategies | "Unroll by factor 4" |
| `compute_early_exit` | Find break conditions | "Use sequential loop" |
| `compute_statement_reordering` | RAW dependency order | "Reorder statements" |
| `compute_scalar_expansion` | Temporary variable needs | "Expand scalar to array" |
| `compute_reduction_type` | Reduction operations | "Use atomic_add" |

---

## Retry Strategy Evolution

### Initial Approach (Tests 1-16)
```
Attempt 1: Initial generation
Attempt 2-3: Retry with error
â†’ Problem: Gets stuck in same error pattern
```

### 5+5 Strategy (Test 17+)
```
Attempts 1-5:  Retry with error feedback
               â””â”€ Show last attempt + error
Attempt 6:     RESET CONTEXT
               â””â”€ Fresh generation without history
Attempts 7-10: New retry sequence
               â””â”€ Fresh perspective on the problem
```

**Result:** +3 functions passed on first try (test16â†’test17)

---

## Test Harness Auto-Generation

For each function, automatically generates:

### 1. **Correctness Test** (`my_triton_implementations/{func}/test_{func}_correctness.py`)
```python
# Auto-generated based on array specs
- Test sizes: [100, 1000, 10000] or [64, 128, 256] for 2D
- Clone tensors for isolation
- Compare outputs: max_error < 1e-3
- Return: PASS/FAIL + error details
```

### 2. **Benchmark Script** (`my_triton_implementations/{func}/benchmark_{func}.py`)
```python
# Auto-generated with timeout handling
- 10 warmup iterations (60s timeout)
- 100 benchmark iterations (60s timeout)
- Record C reference (CPU) and Triton (GPU) times
- Calculate speedup ratio
- Handle timeouts gracefully
```

---

## Prompt Engineering

### Prompt Structure (per function)
```
1. TSVC C code (30-100 lines)
2. Kernel loop to implement (5-20 lines)
3. Array information (types, sizes, access patterns)
4. Static analysis results (0-8 modules)
   â”œâ”€ WAR dependencies (if applicable)
   â”œâ”€ Statement overwrites (if applicable)
   â”œâ”€ Stream compaction (if applicable)
   â””â”€ ... other patterns
5. Function signature requirements (exact parameter names)
6. CRITICAL: Triton compilation rules (12 rules)
   â”œâ”€ NEVER use tl.arange() in loops
   â”œâ”€ NEVER use scalar indexing in kernels
   â”œâ”€ NEVER use non-existent Triton functions
   â””â”€ ... 9 more rules
7. Expected output: Python code only
```

**Total prompt size:** 500-2000 tokens (varies by complexity)

---

# Part 2: Correctness Results

## Historical Progress

*Note: Historical results were measured against LLM-generated PyTorch baseline.*
*Results with TSVC C reference baseline will be measured in new test runs.*

### Design Evolution
- Tests 1-18: PyTorch baseline (LLM-generated, potential bugs)
- Test 19+: TSVC C reference (original ground truth)

**Benefit of new design:** Removes baseline bugs, provides authoritative correctness reference.

---

## Current State (Test 29 Results)

### Summary Metrics
| Metric | Count | Percentage |
|--------|-------|------------|
| **PASSING** | 144 | 95.4% |
| **FAILING** | 7 | 4.6% |
| **Benchmarked** | 147 | 97.4% |
| **Valid Speedups** | 144 | 95.4% |
| **C Ref Timeouts** | 3 | 2.0% |
| **Triton Timeouts** | 0 | 0.0% |

*Results measured against TSVC C reference (ground truth) with checksum-based verification.*

### Pass Rate by Attempt
| Attempt | New Passes | Cumulative | Rate |
|---------|------------|------------|------|
| 1 | 112 | 112 | 74.2% |
| 2-5 | 22 | 134 | 88.7% |
| 6-10 | 10 | 144 | 95.4% |

### Comparison: Test 28 â†’ Test 29
| Metric | Test 28 | Test 29 | Change |
|--------|---------|---------|--------|
| Pass Rate | 96.7% (146/151) | 95.4% (144/151) | -2 functions |
| First-try Success | 82.8% (125) | 74.2% (112) | -13 functions |
| Mean Speedup | 2.55x | 2.57x | +0.8% |
| Max Speedup | 246.41x | 220.28x | -10.6% |

---

## Correctness Results (Test 29)

### 144/151 Functions Pass (95.4%)

Test 29 achieved **95.4% correctness** â€” 144 of 151 functions pass correctness tests.

**7 Failed Functions:**

| Function | Error Type | Root Cause |
|----------|------------|------------|
| **s119** | numerical | Diagonal 2D pattern - complex index computation |
| **s211** | numerical | Statement reorder pattern |
| **s241** | numerical | Conditional assignment pattern |
| **s277** | numerical | Control flow with continue (unsupported in Triton) |
| **s323** | numerical | Nested loop with dependencies |
| **s421** | compilation | tl.arange requires constexpr arguments |
| **s424** | compilation | Sequential loop pattern |

Note: Pass rate varies by run due to LLM non-determinism. Test 28 achieved 146/151 initially,
and 5 failed functions passed on manual re-run.

### Failure Pattern Analysis (Test 29)

**s119** involves a diagonal 2D pattern where indices require complex computation.
All 10 attempts failed with numerical errors due to incorrect index mapping.

**s211** is a statement reorder pattern that passed in Test 28 but failed in Test 29,
demonstrating LLM non-determinism across runs.

**s277** uses `continue` statements in control flow, which Triton does not support.
The LLM struggles to find an equivalent masked implementation.

**s421/s424** consistently fail with compilation errors related to `tl.arange`
requiring constexpr arguments. The LLM cannot escape this pattern despite error
feedback.

**s241, s323** involve complex dependency patterns that the LLM frequently
gets wrong, producing numerical errors.

### Error Summary (Test 29)

| Error Type | Count | Root Cause |
|------------|-------|------------|
| Numerical | 5 | Complex patterns, LLM non-determinism |
| Compilation | 2 | Triton limitations (constexpr, continue) |

---

## Key Correctness Insights

### 1. **95%+ Pass Rate Achievable**
- Test 29: 144/151 (95.4%), Test 28: 146/151 (96.7%)
- Pass rate varies due to LLM non-determinism
- Manual re-runs can recover failed functions (Test 28: 146â†’151 via re-run)

### 2. **Static Analysis Improvements**
- Prefix sum detection with tl.cumsum() strategy
- Strided prefix sum with per-stream parallelization
- Loop distribution with verified_safe analysis
- Statement reordering for RAW dependencies

### 3. **Retry Strategy Effectiveness**
- 5+5 reset strategy: ~20-30 functions recovered via retries
- Some patterns (s421, s424) consistently fail due to Triton limitations
- s277 fails due to unsupported `continue` in Triton kernels

### 4. **LLM Handles Complex Patterns Well**
- 2D loops with dependencies
- Atomic operations for scatter patterns
- Statement reordering for RAW dependencies
- Scalar expansion for temporary variables
- Conditional parallelization
- Stream compaction with cumsum

---

# Part 3: Performance Results

## Benchmark Infrastructure (Test 18)

### New Features
```
âœ… 60-second timeout per section (warmup/benchmark)
âœ… Separate timeout tracking for C reference vs Triton
âœ… Minimum speedup calculation for timeouts
âœ… Graceful error handling
âœ… Machine-readable output format
```

### Timeout Handling
```python
# C reference timeout:
- Baseline too slow (>60s for 100 iterations)
- Report: C ref time = -1ms
- Calculate minimum speedup: 60000ms / triton_time

# Triton timeout:
- Report: Triton time = -1ms

# Both timeout:
- Report: "Both timeout"
```

---

## Performance Summary (Test 29)

### Overall Statistics
| Metric | Test 28 | Test 29 | Change |
|--------|---------|---------|--------|
| **Benchmarked** | 151 | 147 | -4 |
| **Valid Speedups** | 148 | 144 | -4 |
| **C Ref Timeouts** | 3 | 3 | - |
| **Triton Timeouts** | 0 | 0 | - |
| **Mean Speedup** | 2.55x | 2.57x | +0.8% |
| **Min Speedup** | 0.026x | 0.057x | +2.2x |
| **Max Speedup** | 246.41x | 220.28x | -10.6% |

### Performance Distribution (144 functions with valid speedups)

```
Speedup Range          Count    %     Distribution
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
>=2x faster           :  24   (16.7%) â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
1.5x-2x faster        :  10   ( 6.9%) â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
1x-1.5x faster        :  20   (13.9%) â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
0.5x-1x (slower)      :  41   (28.5%) â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
0.1x-0.5x (slower)    :  39   (27.1%) â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
<0.1x (much slower)   :  10   ( 6.9%) â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Triton faster (>=1x)  :  54   (37.5%)
Triton slower (<1x)   :  90   (62.5%)
```

### Visual Distribution Comparison: Test 28 â†’ Test 29

```
                         Test 28                        Test 29                            Change
                    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
<0.1x (slowest)     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  29   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  10             -19  âœ“
0.1x-0.5x           â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  43   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  39        -4
0.5x-1x             â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  28   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  41       +13  âœ“
1x-1.5x             â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  14                 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  20            +6  âœ“
1.5x-2x             â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  12                   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  10                -2
>=2x (fastest)      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  22         â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  24        +2  âœ“
                    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Triton >= 1x:       48 (32.4%)                         54 (37.5%)                      +6  âœ“

Key improvement: Functions moved from slow tiers to faster tiers due to analysis improvements
```

### Performance Shift Analysis
```
                    SLOWER  â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º  FASTER

<0.1x   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  10  (was 29, improved by 19 functions)
0.1-0.5xâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  39
0.5-1x  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  41  (gained 13 functions)
1-1.5x  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  20
1.5-2x  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  10
>=2x    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  24
        | - - - - | - - - - | - - - - | - - - - | - - - - |
        0         10        20        30        40        50
```

---

## Top 10 Fastest Functions (Triton vs C)

| Rank | Function | Speedup | Notes |
|------|----------|---------|-------|
| 1 | s176 | 220.28x | Loop-heavy kernel (C=129.4ms, T=0.6ms) |
| 2 | s451 | 5.96x | Loop interchange |
| 3 | s256 | 4.49x | j-sequential recurrence |
| 4 | s233 | 4.21x | Control flow |
| 5 | s2111 | 3.71x | Double dimension |
| 6 | s2102 | 3.39x | Statement reorder |
| 7 | s231 | 3.38x | Control flow |
| 8 | s343 | 3.26x | Recurrence |
| 9 | s126 | 3.22x | Loop distribution |
| 10 | s2233 | 3.05x | Node splitting |

**Note:** C reference runs on CPU, Triton runs on GPU. s422/s423/s424 show C timeout (>60s).

---

## Bottom 10 Slowest Functions

| Rank | Function | Speedup | Notes |
|------|----------|---------|-------|
| 1 | s277 | 0.057x | Conditional (failed, benchmarked last attempt) |
| 2 | s323 | 0.060x | Nested loop (failed, benchmarked last attempt) |
| 3 | s321 | 0.077x | Loop overhead |
| 4 | s257 | 0.079x | Sequential pattern |
| 5 | s322 | 0.088x | Loop overhead |
| 6 | s318 | 0.103x | Recurrence |
| 7 | s316 | 0.133x | Simple loop |
| 8 | s311 | 0.139x | Simple loop |
| 9 | s331 | 0.139x | Simple loop |
| 10 | s1221 | 0.153x | Strided prefix sum |

**Note:** Slowdowns are primarily due to kernel launch overhead dominating small operations. s422/s423/s424 had C reference timeouts (>60s) with Triton completing in ~10ms.

### Significant Improvements from Test 28 â†’ Test 29

| Function | Test 28 | Test 29 | Improvement | Root Cause |
|----------|---------|---------|-------------|------------|
| s1221 | 0.0004x | 0.15x | **375x** | Strided prefix sum analysis |
| s256 | 0.037x | 4.49x | **121x** | j-sequential recurrence optimization |
| s251 | 0.048x | 0.79x | **16x** | Loop overhead reduction |
| s1251 | 0.069x | 0.96x | **14x** | Strip-vectorizable optimization |
| s253 | 0.087x | 1.01x | **12x** | Scalar expansion fix |
| s3112 | 0.044x | 0.39x | **9x** | Prefix sum with tl.cumsum() |
| s3251 | 0.046x | 0.83x | **18x** | Loop distribution (verified parallel) |
| s222 | 0.026x | 1.11x | **43x** | Statement reorder optimization |
| s261 | 0.074x | 0.98x | **13x** | Statement reorder optimization |
| s221 | 0.082x | 1.08x | **13x** | Induction variable optimization |

---

## Performance by Category (Test 28 (Current))

### Performance Tiers Observed

| Tier | Categories | Avg Speedup | Notes |
|------|------------|-------------|-------|
| ğŸš€ High (>1.5x) | Loop interchange, Control flow | 1.5-5.6x | High parallelism benefit |
| âš¡ Moderate (1-1.5x) | Vector ops, Statement reorder | 1.0-1.5x | Balanced overhead/benefit |
| ğŸŒ Low (<0.5x) | Reductions, Simple loops | 0.02-0.5x | Kernel overhead dominates |

### Key Performance Patterns

**What achieves speedup:**
- Loop-heavy kernels (s176: 10.85x)
- Loop interchange patterns (s451: 6.47x)
- Complex control flow (s273, s274: ~2x)
- Conditional vector operations (vif: 2.05x)
- Computed goto patterns (s442: 2.38x)
- Operations with sufficient arithmetic intensity

**What suffers slowdown:**
- Very simple operations (kernel launch overhead > computation)
- Sequential patterns that can't parallelize
- Small data sizes where transfer overhead dominates

---

## Why GPU Speedups?

### Understanding the Comparison

**The C Reference (CPU):**
```c
// Sequential C loop on CPU
for (int i = 0; i < 32000; i++) {
    a[i] = b[i] + 1.0;
}
```
- **Execution:** Sequential on single CPU core
- **Optimizations:** Compiler auto-vectorization (SIMD)
- **Baseline:** Represents optimized sequential C code

**The Triton Implementation (GPU):**
```python
# Single kernel launch, massively parallel
@triton.jit
def kernel(a_ptr, b_ptr, n, BLOCK_SIZE: tl.constexpr):
    # All 32000 elements in parallel across GPU cores!
```
- **Benefit:** Massive parallelism (thousands of threads)
- **Parallelism:** All elements processed simultaneously
- **Overhead:** Kernel launch + data transfer

### Comparison Context

| Comparison Type | Notes |
|-----------------|-------|
| Triton (GPU) vs C (CPU) | Measures GPU parallelization benefit |
| Triton vs Hand-optimized CUDA | ~0.5-2x (Triton generates efficient code) |

---

## Performance Insights

### 1. **What Triton Excels At**
âœ… Loop interchange patterns (high parallelism)
âœ… 2D operations with dependencies
âœ… Complex control flow
âœ… Induction variable computations
âœ… Stream compaction

### 2. **What May Not Benefit**
âŒ Trivial operations (kernel overhead may dominate)
âŒ Operations with limited parallelism
âŒ Single scalar updates (no parallelism to exploit)

### 3. **Key Observations**
- GPU parallelization provides significant speedups for vectorizable loops
- Kernel launch overhead affects small/trivial operations
- C reference provides a more realistic baseline than Python loops

*Detailed performance insights will be updated after running experiments.*

---

# Conclusions & Future Work

## Key Achievements âœ…

### Infrastructure
- âœ… Fully automated pipeline (TSVC â†’ Triton)
- âœ… 8 static analysis modules integrated
- âœ… Comprehensive test harness generation
- âœ… Retry logic with context reset (5+5 strategy)
- âœ… Timeout-aware benchmarking

### Results (Test 29)
- **Correctness rate:** 95.4% (144/151 functions)
- **First-try success rate:** 74.2% (112/151 functions)
- **Retry recovery:** +32 functions via retries
- **Performance:** 37.5% faster than C, 62.5% slower
- **Max speedup:** 220.28x (s176)
- **Mean speedup:** 2.57x

---

## Limitations & Learnings

### 1. **Prompt Engineering Matters**
- Explicit > Implicit instructions
- Example code is crucial
- s421 failure: missing constexpr instruction

### 2. **Baseline Choice Matters**
- Now using original TSVC C functions as baseline
- C reference provides realistic CPU performance
- GPU vs CPU comparison shows true parallelization benefit

### 3. **Static Analysis Helps**
- 98% vs 95% pass rate with/without analysis
- Not all patterns need analysis
- Some edge cases still missed

### 4. **LLM Consistency**
- 17% need retries
- Some errors persist across attempts
- 5+5 reset helps but not always

---

## Future Work

### Short Term
1. **Fix s421 prompt**
   - Add explicit constexpr instruction
   - Provide working example
   - Test on similar patterns

2. **Run performance experiments**
   - Measure speedups vs C reference baseline
   - Compare against hand-written CUDA
   - Analyze kernel launch overhead impact

3. **Add more analysis modules**
   - Memory access pattern analysis
   - Register pressure prediction
   - Occupancy optimization

### Long Term
1. **Auto-tuning integration**
   - BLOCK_SIZE optimization
   - Grid size tuning
   - Memory layout optimization

2. **Performance optimization**
   - Beyond correctness â†’ optimal code
   - Memory coalescing hints
   - Shared memory utilization

3. **Broader benchmarks**
   - Beyond TSVC
   - Real-world kernels
   - Production workloads

4. **Model improvement**
   - Fine-tune on Triton corpus
   - Few-shot learning with examples
   - Chain-of-thought for complex patterns

---

# Thank You!

## Summary

**Infrastructure:**
- Automated TSVC â†’ Triton pipeline
- 8 static analysis modules
- 5+5 retry strategy
- Comprehensive testing vs C reference

**Results (Test 29):**
- **95.4% correctness** (144/151 functions pass)
- **74.2% first-try success** (112 functions)
- **37.5% achieve GPU speedup** (54/144 functions)
- **Max 220.28x speedup** (s176)
- **Mean 2.57x speedup**

**Impact:**
- Demonstrates LLM capability for specialized GPU kernel generation
- Shows importance of static analysis for complex patterns
- Identifies performance bottlenecks (kernel launch overhead)

---

## Questions?

ğŸ“§ Contact: qin-x18@mails.tsinghua.edu.cn
ğŸ”— Repository: [Add your repo link]
ğŸ“„ Paper: [In progress]

**Next steps:** Improve numerical accuracy, optimize kernel launch overhead, expand patterns!
