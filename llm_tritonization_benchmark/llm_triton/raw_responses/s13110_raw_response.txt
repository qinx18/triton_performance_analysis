# LLM-Generated Triton Implementation for s13110
# Generated: 2025-11-17 17:11:02
# Model: claude-sonnet-4-20250514
# Stop Reason: end_turn
# Input Tokens: 622
# Output Tokens: 1290

================================================================================
PROMPT:
================================================================================
I have a PyTorch/Python baseline implementation that I want to optimize using Triton for GPU acceleration.

Baseline Implementation:
```python
import torch

def s13110_pytorch(aa):
    """
    PyTorch implementation of TSVC s13110 - find maximum element and its indices.
    
    Original C code:
    for (int nl = 0; nl < 100*(iterations/(LEN_2D)); nl++) {
        max = aa[(0)][0];
        xindex = 0;
        yindex = 0;
        for (int i = 0; i < LEN_2D; i++) {
            for (int j = 0; j < LEN_2D; j++) {
                if (aa[i][j] > max) {
                    max = aa[i][j];
                    xindex = i;
                    yindex = j;
                }
            }
        }
        chksum = max + (real_t) xindex + (real_t) yindex;
    }
    """
    aa = aa.contiguous()
    
    # Find maximum value and its linear index
    max_val = torch.max(aa)
    max_idx = torch.argmax(aa)
    
    # Convert linear index to 2D indices
    rows = aa.shape[0]
    xindex = max_idx // rows
    yindex = max_idx % rows
    
    # Calculate checksum (not used in return, but matches C behavior)
    chksum = max_val + xindex.float() + yindex.float()
    
    return aa
```

Please generate a complete, optimized Triton implementation that:
1. Includes a @triton.jit kernel function named `s13110_kernel`
2. Includes a Python wrapper function named `s13110_triton` (NOT `s13110_pytorch`)
3. The wrapper function must have THE EXACT SAME function signature as the baseline (same parameter names and order)
4. Uses appropriate block sizes and memory access patterns
5. Handles edge cases with masking
6. Is functionally equivalent to the baseline (same inputs, same outputs)
7. Returns the same type as the baseline (single tensor or tuple of tensors)
8. Includes brief comments explaining key optimizations

IMPORTANT:
- Wrapper function name: `s13110_triton`
- Function signature must match the baseline exactly (same parameters in same order)
- Accept all parameters the baseline accepts, even if some are modified in-place or used only as outputs

Provide ONLY the Python code, no additional explanation.

================================================================================
RESPONSE:
================================================================================
```python
import torch
import triton
import triton.language as tl

@triton.jit
def s13110_kernel(
    input_ptr,
    max_val_ptr,
    max_idx_ptr,
    n_elements,
    BLOCK_SIZE: tl.constexpr,
):
    """
    Triton kernel to find maximum element and its index in a flattened array.
    Uses block-level reduction for efficient parallel processing.
    """
    pid = tl.program_id(0)
    block_start = pid * BLOCK_SIZE
    offsets = block_start + tl.arange(0, BLOCK_SIZE)
    mask = offsets < n_elements
    
    # Load data with masking for edge cases
    data = tl.load(input_ptr + offsets, mask=mask, other=float('-inf'))
    
    # Find local maximum and its offset within the block
    local_max = tl.max(data)
    local_max_mask = data == local_max
    local_idx_offset = tl.min(tl.where(local_max_mask, tl.arange(0, BLOCK_SIZE), BLOCK_SIZE))
    local_global_idx = block_start + local_idx_offset
    
    # Store results - each block writes its local maximum
    tl.store(max_val_ptr + pid, local_max)
    tl.store(max_idx_ptr + pid, local_global_idx)

@triton.jit
def s13110_final_reduction_kernel(
    max_vals_ptr,
    max_indices_ptr,
    final_max_ptr,
    final_idx_ptr,
    num_blocks,
    BLOCK_SIZE: tl.constexpr,
):
    """
    Final reduction kernel to find global maximum from block-level results.
    """
    pid = tl.program_id(0)
    if pid != 0:
        return
    
    # Load all block maximums
    offsets = tl.arange(0, BLOCK_SIZE)
    mask = offsets < num_blocks
    
    block_maxs = tl.load(max_vals_ptr + offsets, mask=mask, other=float('-inf'))
    block_indices = tl.load(max_indices_ptr + offsets, mask=mask, other=0)
    
    # Find global maximum
    global_max = tl.max(block_maxs)
    global_max_mask = block_maxs == global_max
    final_idx = tl.min(tl.where(global_max_mask, block_indices, 2**31-1))
    
    # Store final results
    tl.store(final_max_ptr, global_max)
    tl.store(final_idx_ptr, final_idx)

def s13110_triton(aa):
    """
    Triton implementation of TSVC s13110 - find maximum element and its indices.
    Uses two-stage reduction: block-level then global reduction for scalability.
    """
    aa = aa.contiguous()
    device = aa.device
    dtype = aa.dtype
    
    # Flatten for easier indexing
    aa_flat = aa.flatten()
    n_elements = aa_flat.numel()
    
    if n_elements == 0:
        return aa
    
    # Choose block size and calculate number of blocks
    BLOCK_SIZE = 1024
    num_blocks = triton.cdiv(n_elements, BLOCK_SIZE)
    
    # Allocate temporary storage for block-level results
    block_max_vals = torch.empty(num_blocks, dtype=dtype, device=device)
    block_max_indices = torch.empty(num_blocks, dtype=torch.int64, device=device)
    
    # Launch first kernel for block-level reductions
    grid = (num_blocks,)
    s13110_kernel[grid](
        aa_flat,
        block_max_vals,
        block_max_indices,
        n_elements,
        BLOCK_SIZE=BLOCK_SIZE,
    )
    
    # Allocate final result storage
    final_max = torch.empty(1, dtype=dtype, device=device)
    final_idx = torch.empty(1, dtype=torch.int64, device=device)
    
    # Launch final reduction kernel
    FINAL_BLOCK_SIZE = triton.next_power_of_2(num_blocks)
    s13110_final_reduction_kernel[(1,)](
        block_max_vals,
        block_max_indices,
        final_max,
        final_idx,
        num_blocks,
        BLOCK_SIZE=FINAL_BLOCK_SIZE,
    )
    
    # Convert linear index back to 2D indices (matching baseline behavior)
    rows = aa.shape[0]
    max_idx = final_idx.item()
    xindex = max_idx // rows
    yindex = max_idx % rows
    
    # Calculate checksum (matches C behavior, though not returned)
    max_val = final_max.item()
    chksum = max_val + float(xindex) + float(yindex)
    
    return aa
```
